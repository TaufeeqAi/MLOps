# MLOps Project - End to End Machine Learning Pipeline

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![MLflow](https://img.shields.io/badge/MLflow-Latest-blue)](https://mlflow.org/)
[![DagsHub](https://img.shields.io/badge/DagsHub-Enabled-green)](https://dagshub.com/)

## ğŸ¯ Project Overview

This project implements a complete end-to-end Machine Learning pipeline following MLOps best practices. It includes data ingestion, validation, transformation, model training, and evaluation using MLflow and DagsHub for experiment tracking and model registry <mcreference link="https://instatus.com/blog/mlops-playbook" index="1">1</mcreference>.

## ğŸš€ Features

- Automated ML Pipeline with modular components
- Data validation and quality checks
- Feature engineering and preprocessing
- Model training and hyperparameter tuning
- Experiment tracking with MLflow
- Model versioning and registry
- Continuous Integration/Deployment ready

## ğŸ› ï¸ Installation

1. Clone the repository:
```bash
git clone <your-repo-url>
cd MLOps
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

## ğŸ“‹ Project Structure

```
MLOps/
â”œâ”€â”€ config/           # Configuration files
â”œâ”€â”€ src/MLOps/        # Source code
â”‚   â”œâ”€â”€ components/   # Pipeline components
â”‚   â”œâ”€â”€ config/      # Configuration utilities
â”‚   â”œâ”€â”€ constants/   # Project constants
â”‚   â”œâ”€â”€ entity/      # Data models/schemas
â”‚   â”œâ”€â”€ pipeline/    # Training pipelines
â”‚   â””â”€â”€ utils/       # Utility functions
â”œâ”€â”€ research/         # Jupyter notebooks for experimentation
â”œâ”€â”€ templates/        # HTML templates
â”œâ”€â”€ mlruns/          # MLflow experiment tracking
â””â”€â”€ tests/           # Unit tests
```

## ğŸ”„ MLOps Pipeline Workflow

1. **Data Ingestion**
   - Raw data collection and storage
   - Data versioning and cataloging

2. **Data Validation**
   - Schema validation
   - Data quality checks
   - Data drift detection

3. **Data Transformation**
   - Feature engineering
   - Data preprocessing
   - Feature scaling and encoding

4. **Model Training**
   - Algorithm selection
   - Hyperparameter tuning
   - Cross-validation

5. **Model Evaluation**
   - Performance metrics tracking
   - Model validation
   - MLflow experiment logging

## ğŸ”§ Configuration

The project uses three main configuration files:

1. `config.yaml`: Main configuration parameters
2. `schema.yaml`: Data schema definition
3. `params.yaml`: Model hyperparameters

## ğŸ“Š Experiment Tracking

All experiments are tracked using MLflow and synchronized with DagsHub. Access the experiment tracking UI at:
```
http://localhost:5000
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request <mcreference link="https://www.welcometothejungle.com/en/articles/btc-readme-documentation-best-practices" index="2">2</mcreference>.

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- MLflow for experiment tracking
- DagsHub for model registry
- All contributors to this project